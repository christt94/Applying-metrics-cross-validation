In this activity, you learned how to apply evaluation metrics and use cross-validation to reliably assess the performance of machine learning models. 

Key takeaways:

Cross-validation provides a more robust performance estimate by training and testing on multiple data splits.

You can calculate multiple evaluation metrics during cross-validation to get a comprehensive view of model performance.

Both classification and regression models benefit from cross-validation, which helps avoid overfitting and ensures reliable performance.

Experiment with different datasets, models, and metrics to further improve your understanding of cross-validation and model evaluation.
